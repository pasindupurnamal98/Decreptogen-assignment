{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae48da98",
   "metadata": {},
   "source": [
    "### üß™ Step 1: Load and Explore the Dataset\n",
    "\n",
    "In this step, we:\n",
    "\n",
    "- üìÑ Loaded the dataset using **Pandas**\n",
    "- üîç Displayed essential information:\n",
    "  - General structure and column data types using `df.info()`\n",
    "  - First few records using `df.head()`\n",
    "  - Descriptive statistics, including for categorical features, using `df.describe(include='all')`\n",
    "- üßº Checked for **missing values** using `df.isnull().sum()`\n",
    "\n",
    "> This initial exploration helps us better understand the raw data and prepares us for the cleaning and preprocessing steps ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a7f7c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2900 entries, 0 to 2899\n",
      "Data columns (total 8 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Time_spent_Alone           2837 non-null   float64\n",
      " 1   Stage_fear                 2827 non-null   object \n",
      " 2   Social_event_attendance    2838 non-null   float64\n",
      " 3   Going_outside              2834 non-null   float64\n",
      " 4   Drained_after_socializing  2848 non-null   object \n",
      " 5   Friends_circle_size        2823 non-null   float64\n",
      " 6   Post_frequency             2835 non-null   float64\n",
      " 7   Personality                2900 non-null   object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 181.4+ KB\n",
      "None\n",
      "   Time_spent_Alone Stage_fear  Social_event_attendance  Going_outside  \\\n",
      "0               4.0         No                      4.0            6.0   \n",
      "1               9.0        Yes                      0.0            0.0   \n",
      "2               9.0        Yes                      1.0            2.0   \n",
      "3               0.0         No                      6.0            7.0   \n",
      "4               3.0         No                      9.0            4.0   \n",
      "\n",
      "  Drained_after_socializing  Friends_circle_size  Post_frequency Personality  \n",
      "0                        No                 13.0             5.0   Extrovert  \n",
      "1                       Yes                  0.0             3.0   Introvert  \n",
      "2                       Yes                  5.0             2.0   Introvert  \n",
      "3                        No                 14.0             8.0   Extrovert  \n",
      "4                        No                  8.0             5.0   Extrovert  \n",
      "        Time_spent_Alone Stage_fear  Social_event_attendance  Going_outside  \\\n",
      "count        2837.000000       2827              2838.000000    2834.000000   \n",
      "unique               NaN          2                      NaN            NaN   \n",
      "top                  NaN         No                      NaN            NaN   \n",
      "freq                 NaN       1417                      NaN            NaN   \n",
      "mean            4.505816        NaN                 3.963354       3.000000   \n",
      "std             3.479192        NaN                 2.903827       2.247327   \n",
      "min             0.000000        NaN                 0.000000       0.000000   \n",
      "25%             2.000000        NaN                 2.000000       1.000000   \n",
      "50%             4.000000        NaN                 3.000000       3.000000   \n",
      "75%             8.000000        NaN                 6.000000       5.000000   \n",
      "max            11.000000        NaN                10.000000       7.000000   \n",
      "\n",
      "       Drained_after_socializing  Friends_circle_size  Post_frequency  \\\n",
      "count                       2848          2823.000000     2835.000000   \n",
      "unique                         2                  NaN             NaN   \n",
      "top                           No                  NaN             NaN   \n",
      "freq                        1441                  NaN             NaN   \n",
      "mean                         NaN             6.268863        3.564727   \n",
      "std                          NaN             4.289693        2.926582   \n",
      "min                          NaN             0.000000        0.000000   \n",
      "25%                          NaN             3.000000        1.000000   \n",
      "50%                          NaN             5.000000        3.000000   \n",
      "75%                          NaN            10.000000        6.000000   \n",
      "max                          NaN            15.000000       10.000000   \n",
      "\n",
      "       Personality  \n",
      "count         2900  \n",
      "unique           2  \n",
      "top      Extrovert  \n",
      "freq          1491  \n",
      "mean           NaN  \n",
      "std            NaN  \n",
      "min            NaN  \n",
      "25%            NaN  \n",
      "50%            NaN  \n",
      "75%            NaN  \n",
      "max            NaN  \n",
      "Time_spent_Alone             63\n",
      "Stage_fear                   73\n",
      "Social_event_attendance      62\n",
      "Going_outside                66\n",
      "Drained_after_socializing    52\n",
      "Friends_circle_size          77\n",
      "Post_frequency               65\n",
      "Personality                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"data/personality_dataset.csv\")\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5d75f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape: (2900, 7)\n",
      "Processed X shape: (2900, 9)\n",
      "Original y shape: (2900,)\n",
      "Encoded y shape: (2900,)\n",
      "Sample of encoded y: [0 1 1 0 0]\n",
      "Sample of processed X (first 5 rows, first 5 columns):\n",
      " [[ 4.  4.  6. 13.  5.]\n",
      " [ 9.  0.  0.  0.  3.]\n",
      " [ 9.  1.  2.  5.  2.]\n",
      " [ 0.  6.  7. 14.  8.]\n",
      " [ 3.  9.  4.  8.  5.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Separate target variable\n",
    "X = df.drop(\"Personality\", axis=1)\n",
    "y = df[\"Personality\"]\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "numerical_cols = X.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "\n",
    "# Preprocessing pipelines for numerical and categorical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Create a preprocessor object using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer, numerical_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(f\"Original X shape: {X.shape}\")\n",
    "print(f\"Processed X shape: {X_processed.shape}\")\n",
    "print(f\"Original y shape: {y.shape}\")\n",
    "print(f\"Encoded y shape: {y_encoded.shape}\")\n",
    "print(\"Sample of encoded y:\", y_encoded[:5])\n",
    "print(\"Sample of processed X (first 5 rows, first 5 columns):\\n\", X_processed[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d97dd93",
   "metadata": {},
   "source": [
    "### üîç Step 2.1: Target Separation & Feature Type Identification\n",
    "\n",
    "- Separated `Personality` as the target variable.\n",
    "- Identified column types:\n",
    "  - Categorical: Textual features requiring encoding\n",
    "  - Numerical: Features that may need imputation or scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c4d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['Stage_fear', 'Drained_after_socializing']\n",
      "Numerical columns: ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Separate target and features\n",
    "X = df.drop(\"Personality\", axis=1) #features\n",
    "y = df[\"Personality\"] #target variable\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "numerical_cols = X.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "\n",
    "print(\"Categorical columns:\", list(categorical_cols))\n",
    "print(\"Numerical columns:\", list(numerical_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42480eb4",
   "metadata": {},
   "source": [
    "### üßº Step 2.2: Preprocessing Pipelines\n",
    "\n",
    "- Numerical columns: Missing values filled with **mean**\n",
    "- Categorical columns:\n",
    "  - Missing values filled with **most frequent** category\n",
    "  - One-hot encoded for ML compatibility\n",
    "\n",
    "handle_unknown=\"ignore\" avoids crashing if new categories appear during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2004971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Numerical transformer pipeline created (Missing values ‚Üí Mean)\n",
      "‚úÖ Categorical transformer pipeline created (Missing values ‚Üí Most frequent, One-Hot Encoding applied)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing pipelines for numerical and categorical features\n",
    "\n",
    "# Numerical pipeline: Impute missing values using the mean\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "print(\"‚úÖ Numerical transformer pipeline created (Missing values ‚Üí Mean)\")\n",
    "\n",
    "# Categorical pipeline: Impute using most frequent value, then One-Hot Encode\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")) #Converts categorical labels into binary vectors\n",
    "])\n",
    "print(\"‚úÖ Categorical transformer pipeline created (Missing values ‚Üí Most frequent, One-Hot Encoding applied)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d0e8a",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è Step 2.3: Combine & Apply Preprocessing\n",
    "\n",
    "Used `ColumnTransformer` to apply preprocessing pipelines to respective column types.  \n",
    "Transformed feature matrix `X` is now ready for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18905ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape: (2900, 7)\n",
      "Processed X shape: (2900, 9)\n"
     ]
    }
   ],
   "source": [
    "# Combine preprocessing using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer, numerical_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Apply transformation to features\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "print(f\"Original X shape: {X.shape}\") # Original shape of features\n",
    "print(f\"Processed X shape: {X_processed.shape}\") # Shape after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d591d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert to DataFrame\n",
    "X_processed_df = pd.DataFrame(X_processed)\n",
    "\n",
    "# Display first 5 rows\n",
    "print(X_processed_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9c1ba",
   "metadata": {},
   "source": [
    "### üéØ Step 2.4: Encoding Target Variable\n",
    "\n",
    "- Used `LabelEncoder` to convert string labels (e.g., \"Introvert\", \"Extrovert\") into numerical form.\n",
    "- This encoding is essential for training classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15d8ca2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original y shape: (2900,)\n",
      "Encoded y shape: (2900,)\n",
      "Sample encoded labels: [0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(f\"Original y shape: {y.shape}\")\n",
    "print(f\"Encoded y shape: {y_encoded.shape}\")\n",
    "print(\"Sample encoded labels:\", y_encoded[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf3d35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp311-cp311-win_amd64.whl (10.7 MB)\n",
      "     ---------------------------------------- 10.7/10.7 MB 4.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\pcadmin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (2.2.5)\n",
      "Collecting scipy>=1.8.0\n",
      "  Downloading scipy-1.15.3-cp311-cp311-win_amd64.whl (41.2 MB)\n",
      "     ---------------------------------------- 41.2/41.2 MB 4.5 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.7.0 scipy-1.15.3 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11587ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best Hyperparameters: {'classifier__bootstrap': True, 'classifier__max_depth': None, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 100}\n",
      "\n",
      "Training Set Evaluation:\n",
      "Accuracy: 0.9366\n",
      "Precision: 0.9368\n",
      "Recall: 0.9366\n",
      "F1-Score: 0.9366\n",
      "\n",
      "Testing Set Evaluation:\n",
      "Accuracy: 0.9293\n",
      "Precision: 0.9296\n",
      "Recall: 0.9293\n",
      "F1-Score: 0.9293\n",
      "Confusion Matrix:\n",
      " [[278  24]\n",
      " [ 17 261]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# Define the preprocessor (update according to your pipeline)\n",
    "# Example: Assuming 'preprocessor' is already defined as part of your pipeline\n",
    "# preprocessor = ... \n",
    "\n",
    "# Hyperparameter grid for RandomForestClassifier\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__bootstrap': [True, False],\n",
    "}\n",
    "\n",
    "# Create the pipeline with preprocessing and classifier\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters and the corresponding model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "print(\"\\nTraining Set Evaluation:\")\n",
    "print(f\"Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Precision: {train_precision:.4f}\")\n",
    "print(f\"Recall: {train_recall:.4f}\")\n",
    "print(f\"F1-Score: {train_f1:.4f}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nTesting Set Evaluation:\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"F1-Score: {test_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", test_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48604ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (2320, 9)\n",
      "Test set shape: (580, 9)\n",
      "\n",
      "==================================================\n",
      "Tuning Random Forest...\n",
      "==================================================\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Best parameters for Random Forest:\n",
      "  max_depth: 10\n",
      "  max_features: sqrt\n",
      "  min_samples_leaf: 1\n",
      "  min_samples_split: 2\n",
      "  n_estimators: 100\n",
      "Best cross-validation score: 0.9388\n",
      "\n",
      "==================================================\n",
      "Tuning Gradient Boosting...\n",
      "==================================================\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best parameters for Gradient Boosting:\n",
      "  learning_rate: 0.05\n",
      "  max_depth: 3\n",
      "  min_samples_leaf: 1\n",
      "  min_samples_split: 2\n",
      "  n_estimators: 100\n",
      "Best cross-validation score: 0.9384\n",
      "\n",
      "==================================================\n",
      "Tuning SVM...\n",
      "==================================================\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best parameters for SVM:\n",
      "  C: 0.1\n",
      "  gamma: scale\n",
      "  kernel: rbf\n",
      "Best cross-validation score: 0.9388\n",
      "\n",
      "==================================================\n",
      "Tuning Logistic Regression...\n",
      "==================================================\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters for Logistic Regression:\n",
      "  C: 0.01\n",
      "  penalty: l1\n",
      "  solver: liblinear\n",
      "Best cross-validation score: 0.9388\n",
      "\n",
      "============================================================\n",
      "MODEL COMPARISON\n",
      "============================================================\n",
      "Random Forest        | CV Score: 0.9388\n",
      "Gradient Boosting    | CV Score: 0.9384\n",
      "SVM                  | CV Score: 0.9388\n",
      "Logistic Regression  | CV Score: 0.9388\n",
      "\n",
      "Best performing model: Random Forest (CV Score: 0.9388)\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION - Random Forest\n",
      "============================================================\n",
      "Test Accuracy: 0.9138\n",
      "Cross-validation Score: 0.9388\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Extrovert       0.94      0.89      0.91       298\n",
      "   Introvert       0.89      0.94      0.91       282\n",
      "\n",
      "    accuracy                           0.91       580\n",
      "   macro avg       0.91      0.91      0.91       580\n",
      "weighted avg       0.91      0.91      0.91       580\n",
      "\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "   1. Drained_after_socializing_No   | Importance: 0.2796\n",
      "   2. Stage_fear_Yes                 | Importance: 0.1766\n",
      "   3. Social_event_attendance        | Importance: 0.1556\n",
      "   4. Drained_after_socializing_Yes  | Importance: 0.1322\n",
      "   5. Stage_fear_No                  | Importance: 0.0881\n",
      "   6. Going_outside                  | Importance: 0.0588\n",
      "   7. Time_spent_Alone               | Importance: 0.0495\n",
      "   8. Post_frequency                 | Importance: 0.0324\n",
      "   9. Friends_circle_size            | Importance: 0.0272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# Define models and their hyperparameter grids\n",
    "models_and_params = {\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [10, 20, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'max_features': ['sqrt', 'log2']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'Gradient Boosting': {\n",
    "        'model': GradientBoostingClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'learning_rate': [0.05, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'min_samples_split': [2, 5],\n",
    "            'min_samples_leaf': [1, 2]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'SVM': {\n",
    "        'model': SVC(random_state=42),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'kernel': ['rbf', 'linear'],\n",
    "            'gamma': ['scale', 'auto', 0.001, 0.01]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'params': {\n",
    "            'C': [0.01, 0.1, 1, 10, 100],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear', 'saga']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "# Perform hyperparameter tuning for each model\n",
    "for model_name, model_info in models_and_params.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Tuning {model_name}...\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Create GridSearchCV object\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model_info['model'],\n",
    "        param_grid=model_info['params'],\n",
    "        cv=5,  # 5-fold cross-validation\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,  # Use all available cores\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit the grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Store results\n",
    "    results[model_name] = {\n",
    "        'best_estimator': grid_search.best_estimator_,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_cv_score': grid_search.best_score_,\n",
    "        'grid_search': grid_search\n",
    "    }\n",
    "    \n",
    "    print(f\"Best parameters for {model_name}:\")\n",
    "    for param, value in grid_search.best_params_.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Compare all models\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "best_model_name = None\n",
    "best_score = 0\n",
    "\n",
    "for model_name, result in results.items():\n",
    "    cv_score = result['best_cv_score']\n",
    "    print(f\"{model_name:20} | CV Score: {cv_score:.4f}\")\n",
    "    \n",
    "    if cv_score > best_score:\n",
    "        best_score = cv_score\n",
    "        best_model_name = model_name\n",
    "\n",
    "print(f\"\\nBest performing model: {best_model_name} (CV Score: {best_score:.4f})\")\n",
    "\n",
    "# Evaluate the best model on test set\n",
    "best_model = results[best_model_name]['best_estimator']\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FINAL EVALUATION - {best_model_name}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Cross-validation Score: {best_score:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\nClassification Report:\")\n",
    "target_names = label_encoder.classes_\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# Feature importance (if available)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    print(f\"\\nTop 10 Most Important Features:\")\n",
    "    feature_importance = best_model.feature_importances_\n",
    "    # Get feature names after preprocessing\n",
    "    feature_names = []\n",
    "    \n",
    "    # Add numerical feature names\n",
    "    feature_names.extend(numerical_cols.tolist())\n",
    "    \n",
    "    # Add categorical feature names (after one-hot encoding)\n",
    "    if len(categorical_cols) > 0:\n",
    "        cat_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_cols)\n",
    "        feature_names.extend(cat_feature_names.tolist())\n",
    "    \n",
    "    # Sort features by importance\n",
    "    importance_indices = np.argsort(feature_importance)[::-1]\n",
    "    \n",
    "    for i in range(min(10, len(feature_names))):\n",
    "        idx = importance_indices[i]\n",
    "        print(f\"  {i+1:2d}. {feature_names[idx]:30} | Importance: {feature_importance[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f65ae28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Evaluation Metrics Table:\n",
      "\n",
      "   Metric  Score\n",
      " Accuracy 0.9138\n",
      " F1 Score 0.9135\n",
      "Precision 0.8919\n",
      "   Recall 0.9362\n",
      " CV Score 0.9388\n"
     ]
    }
   ],
   "source": [
    "# Tabular output of classification metrics\n",
    "import pandas as pd\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Metric\": ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'CV Score'],\n",
    "    \"Score\": [acc, f1, prec, recall, results[best_model_name]['best_cv_score']]\n",
    "})\n",
    "\n",
    "# Round values\n",
    "metrics_df['Score'] = metrics_df['Score'].apply(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "# Display nicely\n",
    "print(\"\\nüìã Evaluation Metrics Table:\\n\")\n",
    "print(metrics_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c303de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e95f3f",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è Step 1: Import Libraries and Split Dataset\n",
    "\n",
    "We start by importing all required libraries and then split our dataset into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0db2c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (2320, 9)\n",
      "Test set shape: (580, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c544eb1",
   "metadata": {},
   "source": [
    "### ü§ñ Step 2: Define Models and Hyperparameter Grids\n",
    "\n",
    "We define multiple classifiers and their tuning parameters for `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f19c9e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model & hyperparameter grids defined:\n",
      "  ‚Ä¢ Random Forest ‚Üí 5 hyperparameter(s) to tune\n",
      "  ‚Ä¢ Gradient Boosting ‚Üí 5 hyperparameter(s) to tune\n",
      "  ‚Ä¢ SVM ‚Üí 3 hyperparameter(s) to tune\n",
      "  ‚Ä¢ Logistic Regression ‚Üí 3 hyperparameter(s) to tune\n"
     ]
    }
   ],
   "source": [
    "# Define models and their hyperparameter grids\n",
    "models_and_params = {\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [10, 20, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'max_features': ['sqrt', 'log2']\n",
    "        }\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'model': GradientBoostingClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'learning_rate': [0.05, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'min_samples_split': [2, 5],\n",
    "            'min_samples_leaf': [1, 2]\n",
    "        }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVC(random_state=42),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'kernel': ['rbf', 'linear'],\n",
    "            'gamma': ['scale', 'auto', 0.001, 0.01]\n",
    "        }\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'params': {\n",
    "            'C': [0.01, 0.1, 1, 10, 100],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear', 'saga']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Model & hyperparameter grids defined:\")\n",
    "for model_name in models_and_params:\n",
    "    param_count = len(models_and_params[model_name]['params'])\n",
    "    print(f\"  ‚Ä¢ {model_name} ‚Üí {param_count} hyperparameter(s) to tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af1e34b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\pcadmin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\pcadmin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61d6bb1",
   "metadata": {},
   "source": [
    "### üß™ Step 3: Train, Tune, and Evaluate All Models\n",
    "\n",
    "We tune and evaluate each model using `GridSearchCV`, storing all evaluations for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5899b286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚è≥ Training: Random Forest:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üîß TUNING MODEL: RANDOM FOREST\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚è≥ Training: Gradient Boosting:  25%|‚ñà‚ñà‚ñå       | 1/4 [02:02<06:08, 122.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Results for Random Forest:\n",
      "   ‚ñ∏ Best CV Accuracy   : 0.9388\n",
      "   ‚ñ∏ Train Accuracy     : 0.9427\n",
      "   ‚ñ∏ Test Accuracy      : 0.9138\n",
      "   ‚ñ∏ Precision (weighted): 0.9149\n",
      "   ‚ñ∏ Recall (weighted)   : 0.9138\n",
      "   ‚ñ∏ F1 Score (weighted) : 0.9138\n",
      "   ‚ñ∏ Overfitting (ŒîTrain-Test): 0.0289\n",
      "   ‚úÖ Best Params: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "======================================================================\n",
      "üîß TUNING MODEL: GRADIENT BOOSTING\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚è≥ Training: SVM:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [03:33<03:27, 103.69s/it]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Results for Gradient Boosting:\n",
      "   ‚ñ∏ Best CV Accuracy   : 0.9384\n",
      "   ‚ñ∏ Train Accuracy     : 0.9388\n",
      "   ‚ñ∏ Test Accuracy      : 0.9172\n",
      "   ‚ñ∏ Precision (weighted): 0.9183\n",
      "   ‚ñ∏ Recall (weighted)   : 0.9172\n",
      "   ‚ñ∏ F1 Score (weighted) : 0.9172\n",
      "   ‚ñ∏ Overfitting (ŒîTrain-Test): 0.0216\n",
      "   ‚úÖ Best Params: {'learning_rate': 0.05, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "======================================================================\n",
      "üîß TUNING MODEL: SVM\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚è≥ Training: Logistic Regression:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [16:13<06:43, 403.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Results for SVM:\n",
      "   ‚ñ∏ Best CV Accuracy   : 0.9388\n",
      "   ‚ñ∏ Train Accuracy     : 0.9388\n",
      "   ‚ñ∏ Test Accuracy      : 0.9172\n",
      "   ‚ñ∏ Precision (weighted): 0.9183\n",
      "   ‚ñ∏ Recall (weighted)   : 0.9172\n",
      "   ‚ñ∏ F1 Score (weighted) : 0.9172\n",
      "   ‚ñ∏ Overfitting (ŒîTrain-Test): 0.0216\n",
      "   ‚úÖ Best Params: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "======================================================================\n",
      "üîß TUNING MODEL: LOGISTIC REGRESSION\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚è≥ Training: Logistic Regression: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [16:14<00:00, 243.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Results for Logistic Regression:\n",
      "   ‚ñ∏ Best CV Accuracy   : 0.9388\n",
      "   ‚ñ∏ Train Accuracy     : 0.9388\n",
      "   ‚ñ∏ Test Accuracy      : 0.9172\n",
      "   ‚ñ∏ Precision (weighted): 0.9183\n",
      "   ‚ñ∏ Recall (weighted)   : 0.9172\n",
      "   ‚ñ∏ F1 Score (weighted) : 0.9172\n",
      "   ‚ñ∏ Overfitting (ŒîTrain-Test): 0.0216\n",
      "   ‚úÖ Best Params: {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# üåü Store detailed results\n",
    "detailed_results = {}\n",
    "accuracy_comparison = []\n",
    "\n",
    "# Prepare loop with progress bar\n",
    "models_iter = tqdm(models_and_params.items(), desc=\"üîÑ Training Models\", leave=True)\n",
    "\n",
    "# üöÄ Train and evaluate each model\n",
    "for model_name, model_info in models_iter:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üîß TUNING MODEL: {model_name.upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Set the progress bar description to current model\n",
    "    models_iter.set_description(f\"‚è≥ Training: {model_name}\")\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model_info['model'],\n",
    "        param_grid=model_info['params'],\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # üß† Train the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # ‚úÖ Predict\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    # üìä Compute metrics\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    cv_accuracy = grid_search.best_score_\n",
    "    test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "    test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "    # üì¶ Store detailed results for later\n",
    "    detailed_results[model_name] = {\n",
    "        'best_estimator': best_model,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'cv_accuracy': cv_accuracy,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_precision': test_precision,\n",
    "        'test_recall': test_recall,\n",
    "        'test_f1': test_f1,\n",
    "        'y_pred': y_test_pred,\n",
    "        'grid_search': grid_search\n",
    "    }\n",
    "\n",
    "    # üìù Append to summary table\n",
    "    accuracy_comparison.append({\n",
    "        'Model': model_name,\n",
    "        'CV_Accuracy': cv_accuracy,\n",
    "        'Train_Accuracy': train_accuracy,\n",
    "        'Test_Accuracy': test_accuracy,\n",
    "        'Test_Precision': test_precision,\n",
    "        'Test_Recall': test_recall,\n",
    "        'Test_F1': test_f1,\n",
    "        'Overfitting': train_accuracy - test_accuracy\n",
    "    })\n",
    "\n",
    "    # üñ®Ô∏è Print Summary Per Model\n",
    "    print(f\"\\nüìä Results for {model_name}:\")\n",
    "    print(\"   ‚ñ∏ Best CV Accuracy   :\", f\"{cv_accuracy:.4f}\")\n",
    "    print(\"   ‚ñ∏ Train Accuracy     :\", f\"{train_accuracy:.4f}\")\n",
    "    print(\"   ‚ñ∏ Test Accuracy      :\", f\"{test_accuracy:.4f}\")\n",
    "    print(\"   ‚ñ∏ Precision (weighted):\", f\"{test_precision:.4f}\")\n",
    "    print(\"   ‚ñ∏ Recall (weighted)   :\", f\"{test_recall:.4f}\")\n",
    "    print(\"   ‚ñ∏ F1 Score (weighted) :\", f\"{test_f1:.4f}\")\n",
    "    print(\"   ‚ñ∏ Overfitting (ŒîTrain-Test):\", f\"{train_accuracy - test_accuracy:.4f}\")\n",
    "    print(\"   ‚úÖ Best Params:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53acda2d",
   "metadata": {},
   "source": [
    "### üìä Step 4: Compare and Rank Models\n",
    "\n",
    "We create a structured table to rank models based on their scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "919615e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "COMPREHENSIVE MODEL COMPARISON\n",
      "====================================================================================================\n",
      "                 Model  CV_Accuracy  Train_Accuracy  Test_Accuracy  \\\n",
      "0        Random Forest       0.9388          0.9427         0.9138   \n",
      "1    Gradient Boosting       0.9384          0.9388         0.9172   \n",
      "2                  SVM       0.9388          0.9388         0.9172   \n",
      "3  Logistic Regression       0.9388          0.9388         0.9172   \n",
      "\n",
      "   Test_Precision  Test_Recall  Test_F1  Overfitting  \n",
      "0          0.9149       0.9138   0.9138       0.0289  \n",
      "1          0.9183       0.9172   0.9172       0.0216  \n",
      "2          0.9183       0.9172   0.9172       0.0216  \n",
      "3          0.9183       0.9172   0.9172       0.0216  \n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame to compare models\n",
    "comparison_df = pd.DataFrame(accuracy_comparison).round(4)\n",
    "\n",
    "# Rank by various metrics\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON\")\n",
    "print(f\"{'='*100}\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Show best per metric\n",
    "best_cv_model = comparison_df.loc[comparison_df['CV_Accuracy'].idxmax(), 'Model']\n",
    "best_test_model = comparison_df.loc[comparison_df['Test_Accuracy'].idxmax(), 'Model']\n",
    "best_f1_model = comparison_df.loc[comparison_df['Test_F1'].idxmax(), 'Model']\n",
    "least_overfitting = comparison_df.loc[comparison_df['Overfitting'].idxmin(), 'Model']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a37392",
   "metadata": {},
   "source": [
    "### üèÜ Step 5: Select Final Model Based on Test Accuracy\n",
    "\n",
    "We select the best performing model based on test accuracy and show all its metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f396f93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECTED MODEL: Gradient Boosting\n",
      "Test Accuracy: 0.9172\n",
      "CV Accuracy: 0.9384\n",
      "F1-Score: 0.9172\n"
     ]
    }
   ],
   "source": [
    "selected_model_name = best_test_model\n",
    "selected_model_results = detailed_results[selected_model_name]\n",
    "selected_model = selected_model_results['best_estimator']\n",
    "selected_params = selected_model_results['best_params']\n",
    "\n",
    "print(f\"\\nSELECTED MODEL: {selected_model_name}\")\n",
    "print(f\"Test Accuracy: {selected_model_results['test_accuracy']:.4f}\")\n",
    "print(f\"CV Accuracy: {selected_model_results['cv_accuracy']:.4f}\")\n",
    "print(f\"F1-Score: {selected_model_results['test_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186ac9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### üìã Step 6: Classification Report & Confusion Matrix for Selected Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27241815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Extrovert       0.94      0.90      0.92       298\n",
      "   Introvert       0.90      0.94      0.92       282\n",
      "\n",
      "    accuracy                           0.92       580\n",
      "   macro avg       0.92      0.92      0.92       580\n",
      "weighted avg       0.92      0.92      0.92       580\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[267  31]\n",
      " [ 17 265]]\n",
      "\n",
      "Class-wise Accuracy:\n",
      "  Extrovert: 0.8960\n",
      "  Introvert: 0.9397\n"
     ]
    }
   ],
   "source": [
    "# Evaluate selected model\n",
    "target_names = label_encoder.classes_\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, selected_model_results['y_pred'], target_names=target_names))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, selected_model_results['y_pred'])\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClass-wise Accuracy:\")\n",
    "for i, class_name in enumerate(target_names):\n",
    "    class_accuracy = cm[i, i] / cm[i, :].sum()\n",
    "    print(f\"  {class_name}: {class_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab34658a",
   "metadata": {},
   "source": [
    "### üîç Step 7: Feature Importance (Tree-based Models Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ed23693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 Most Important Features:\n",
      "                      Feature  Importance\n",
      " Drained_after_socializing_No    0.497887\n",
      "Drained_after_socializing_Yes    0.428492\n",
      "               Post_frequency    0.049290\n",
      "          Friends_circle_size    0.007182\n",
      "             Time_spent_Alone    0.007137\n",
      "      Social_event_attendance    0.006614\n",
      "                Going_outside    0.003362\n",
      "                Stage_fear_No    0.000035\n",
      "               Stage_fear_Yes    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Feature importance for tree-based models\n",
    "if hasattr(selected_model, 'feature_importances_'):\n",
    "    feature_importance = selected_model.feature_importances_\n",
    "\n",
    "    feature_names = numerical_cols.tolist()\n",
    "    if len(categorical_cols) > 0:\n",
    "        cat_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_cols)\n",
    "        feature_names.extend(cat_feature_names.tolist())\n",
    "\n",
    "    feature_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importance\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "\n",
    "    print(\"Top 15 Most Important Features:\")\n",
    "    print(feature_df.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b756e9",
   "metadata": {},
   "source": [
    "### üíæ Step 8: Save Models, Pipeline, Comparison Data, and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b950e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Build complete pipeline\n",
    "complete_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', selected_model)\n",
    "])\n",
    "complete_pipeline.fit(X, y_encoded)\n",
    "\n",
    "# Save models and metadata\n",
    "joblib.dump(complete_pipeline, 'best_personality_model_pipeline.pkl')\n",
    "joblib.dump(selected_model, 'best_personality_model.pkl')\n",
    "joblib.dump(preprocessor, 'preprocessor.pkl')\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "comparison_df.to_csv('model_comparison_results.csv', index=False)\n",
    "\n",
    "# Save full results\n",
    "with open('detailed_model_results.pkl', 'wb') as f:\n",
    "    pickle.dump(detailed_results, f)\n",
    "\n",
    "model_info = {\n",
    "    'selected_model_name': selected_model_name,\n",
    "    'selection_criteria': 'Highest Test Accuracy',\n",
    "    'model_comparison': comparison_df.to_dict('records'),\n",
    "    'best_params': selected_params,\n",
    "    'performance_metrics': {\n",
    "        'cv_accuracy': selected_model_results['cv_accuracy'],\n",
    "        'test_accuracy': selected_model_results['test_accuracy'],\n",
    "        'test_precision': selected_model_results['test_precision'],\n",
    "        'test_recall': selected_model_results['test_recall'],\n",
    "        'test_f1': selected_model_results['test_f1']\n",
    "    },\n",
    "    'feature_names': feature_names if 'feature_names' in locals() else None,\n",
    "    'target_classes': target_names.tolist()\n",
    "}\n",
    "\n",
    "with open('comprehensive_model_info.pkl', 'wb') as f:\n",
    "    pickle.dump(model_info, f)\n",
    "\n",
    "print(\"‚úÖ All results and model artifacts have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00b95c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data prediction: Extrovert\n"
     ]
    }
   ],
   "source": [
    "# Example of making a prediction on new data\n",
    "# Let's create a sample new data point (ensure it has the same columns as the training data)\n",
    "new_data = pd.DataFrame([{\n",
    "    'Time_spent_Alone': 5,\n",
    "    'Stage_fear': 'No',\n",
    "    'Social_event_attendance': 3,\n",
    "    'Going_outside': 7,\n",
    "    'Drained_after_socializing': 'No',\n",
    "    'Friends_circle_size': 10,\n",
    "    'Post_frequency': 6\n",
    "}])\n",
    "\n",
    "# Make prediction\n",
    "new_prediction_encoded = best_model.predict(new_data)\n",
    "new_prediction_personality = label_encoder.inverse_transform(new_prediction_encoded)\n",
    "\n",
    "print(f\"New data prediction: {new_prediction_personality[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa4a8b4",
   "metadata": {},
   "source": [
    "New Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8aaf8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data prediction: Extrovert\n"
     ]
    }
   ],
   "source": [
    "new_data = pd.DataFrame([{\n",
    "    'Time_spent_Alone': 5,\n",
    "    'Stage_fear': 'No',\n",
    "    'Social_event_attendance': 3,\n",
    "    'Going_outside': 7,\n",
    "    'Drained_after_socializing': 'No',\n",
    "    'Friends_circle_size': 10,\n",
    "    'Post_frequency': 6\n",
    "}])\n",
    "\n",
    "# Ensure new_data has the same preprocessing applied\n",
    "new_data_preprocessed = preprocessor.transform(new_data)\n",
    "\n",
    "# Make prediction\n",
    "new_prediction_encoded = best_model.predict(new_data_preprocessed)\n",
    "new_prediction_personality = label_encoder.inverse_transform(new_prediction_encoded)\n",
    "\n",
    "print(f\"New data prediction: {new_prediction_personality[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f4d989e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the entire dataset: 0.9352\n",
      "   Time_spent_Alone Stage_fear  Social_event_attendance  Going_outside  \\\n",
      "0               4.0         No                      4.0            6.0   \n",
      "1               9.0        Yes                      0.0            0.0   \n",
      "2               9.0        Yes                      1.0            2.0   \n",
      "3               0.0         No                      6.0            7.0   \n",
      "4               3.0         No                      9.0            4.0   \n",
      "\n",
      "  Drained_after_socializing  Friends_circle_size  Post_frequency Personality  \\\n",
      "0                        No                 13.0             5.0   Extrovert   \n",
      "1                       Yes                  0.0             3.0   Introvert   \n",
      "2                       Yes                  5.0             2.0   Introvert   \n",
      "3                        No                 14.0             8.0   Extrovert   \n",
      "4                        No                  8.0             5.0   Extrovert   \n",
      "\n",
      "   Predicted  \n",
      "0  Extrovert  \n",
      "1  Introvert  \n",
      "2  Introvert  \n",
      "3  Extrovert  \n",
      "4  Extrovert  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"data/personality_dataset.csv\")\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=[\"Personality\"])  # Assuming \"Personality\" is the target column\n",
    "y_actual = df[\"Personality\"]\n",
    "\n",
    "# Encode the target variable (if not already encoded)\n",
    "# Assuming label_encoder was used earlier for encoding the \"Personality\" column\n",
    "y_encoded_actual = label_encoder.transform(y_actual)\n",
    "\n",
    "# Make predictions on the entire dataset\n",
    "y_pred_encoded = best_model.predict(X)\n",
    "\n",
    "# Decode the predictions to original labels\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# Add the predictions as a new column to the DataFrame\n",
    "df[\"Predicted\"] = y_pred\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(\"data/personality_dataset_with_predictions.csv\", index=False)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = accuracy_score(y_actual, y_pred)\n",
    "print(f\"Accuracy on the entire dataset: {accuracy:.4f}\")\n",
    "\n",
    "# Optionally, print the first few rows to verify the output\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30b6538b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Predictions saved to: data/personality_dataset_with_predictions2.csv\n",
      "\n",
      "üìà Model Evaluation on Full Dataset\n",
      "----------------------------------------\n",
      "‚úÖ Accuracy: 0.9345\n",
      "\n",
      "üîç Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Extrovert       0.95      0.93      0.94      1491\n",
      "   Introvert       0.92      0.94      0.93      1409\n",
      "\n",
      "    accuracy                           0.93      2900\n",
      "   macro avg       0.93      0.93      0.93      2900\n",
      "weighted avg       0.93      0.93      0.93      2900\n",
      "\n",
      "\n",
      "üî¢ Sample Predictions:\n",
      "  Personality  Predicted\n",
      "0   Extrovert  Extrovert\n",
      "1   Introvert  Introvert\n",
      "2   Introvert  Introvert\n",
      "3   Extrovert  Extrovert\n",
      "4   Extrovert  Extrovert\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# üìÇ Load saved pipeline & label encoder\n",
    "pipeline = joblib.load('best_personality_model_pipeline.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl')  # Used to decode prediction outputs\n",
    "\n",
    "# üìÑ Load raw dataset (same format used during training)\n",
    "df = pd.read_csv(\"data/personality_dataset.csv\")\n",
    "\n",
    "# üéØ Separate features and target\n",
    "X = df.drop(columns=[\"Personality\"])\n",
    "y_actual = df[\"Personality\"]\n",
    "\n",
    "# üîÅ Encode actual target using label encoder\n",
    "y_encoded_actual = label_encoder.transform(y_actual)\n",
    "\n",
    "# ‚úÖ Predict using full pipeline with preprocessing included\n",
    "y_pred_encoded = pipeline.predict(X)\n",
    "\n",
    "# üîÅ Decode predictions back to original \"Introvert\"/\"Extrovert\"\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# ‚ûï Add predictions to the original DataFrame\n",
    "df[\"Predicted\"] = y_pred\n",
    "\n",
    "# üíæ Save to a new CSV\n",
    "output_path = \"data/personality_dataset_with_predictions2.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"‚úÖ Predictions saved to: {output_path}\")\n",
    "\n",
    "# üìä Evaluate accuracy & display classification report\n",
    "accuracy = accuracy_score(y_actual, y_pred)\n",
    "print(\"\\nüìà Model Evaluation on Full Dataset\")\n",
    "print(\"----------------------------------------\")\n",
    "print(f\"‚úÖ Accuracy: {accuracy:.4f}\\n\")\n",
    "print(\"üîç Classification Report:\")\n",
    "print(classification_report(y_actual, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# üßæ Sample preview\n",
    "print(\"\\nüî¢ Sample Predictions:\")\n",
    "print(df[['Personality', 'Predicted']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
