{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a7f7c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2900 entries, 0 to 2899\n",
      "Data columns (total 8 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Time_spent_Alone           2837 non-null   float64\n",
      " 1   Stage_fear                 2827 non-null   object \n",
      " 2   Social_event_attendance    2838 non-null   float64\n",
      " 3   Going_outside              2834 non-null   float64\n",
      " 4   Drained_after_socializing  2848 non-null   object \n",
      " 5   Friends_circle_size        2823 non-null   float64\n",
      " 6   Post_frequency             2835 non-null   float64\n",
      " 7   Personality                2900 non-null   object \n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 181.4+ KB\n",
      "None\n",
      "   Time_spent_Alone Stage_fear  Social_event_attendance  Going_outside  \\\n",
      "0               4.0         No                      4.0            6.0   \n",
      "1               9.0        Yes                      0.0            0.0   \n",
      "2               9.0        Yes                      1.0            2.0   \n",
      "3               0.0         No                      6.0            7.0   \n",
      "4               3.0         No                      9.0            4.0   \n",
      "\n",
      "  Drained_after_socializing  Friends_circle_size  Post_frequency Personality  \n",
      "0                        No                 13.0             5.0   Extrovert  \n",
      "1                       Yes                  0.0             3.0   Introvert  \n",
      "2                       Yes                  5.0             2.0   Introvert  \n",
      "3                        No                 14.0             8.0   Extrovert  \n",
      "4                        No                  8.0             5.0   Extrovert  \n",
      "        Time_spent_Alone Stage_fear  Social_event_attendance  Going_outside  \\\n",
      "count        2837.000000       2827              2838.000000    2834.000000   \n",
      "unique               NaN          2                      NaN            NaN   \n",
      "top                  NaN         No                      NaN            NaN   \n",
      "freq                 NaN       1417                      NaN            NaN   \n",
      "mean            4.505816        NaN                 3.963354       3.000000   \n",
      "std             3.479192        NaN                 2.903827       2.247327   \n",
      "min             0.000000        NaN                 0.000000       0.000000   \n",
      "25%             2.000000        NaN                 2.000000       1.000000   \n",
      "50%             4.000000        NaN                 3.000000       3.000000   \n",
      "75%             8.000000        NaN                 6.000000       5.000000   \n",
      "max            11.000000        NaN                10.000000       7.000000   \n",
      "\n",
      "       Drained_after_socializing  Friends_circle_size  Post_frequency  \\\n",
      "count                       2848          2823.000000     2835.000000   \n",
      "unique                         2                  NaN             NaN   \n",
      "top                           No                  NaN             NaN   \n",
      "freq                        1441                  NaN             NaN   \n",
      "mean                         NaN             6.268863        3.564727   \n",
      "std                          NaN             4.289693        2.926582   \n",
      "min                          NaN             0.000000        0.000000   \n",
      "25%                          NaN             3.000000        1.000000   \n",
      "50%                          NaN             5.000000        3.000000   \n",
      "75%                          NaN            10.000000        6.000000   \n",
      "max                          NaN            15.000000       10.000000   \n",
      "\n",
      "       Personality  \n",
      "count         2900  \n",
      "unique           2  \n",
      "top      Extrovert  \n",
      "freq          1491  \n",
      "mean           NaN  \n",
      "std            NaN  \n",
      "min            NaN  \n",
      "25%            NaN  \n",
      "50%            NaN  \n",
      "75%            NaN  \n",
      "max            NaN  \n",
      "Time_spent_Alone             63\n",
      "Stage_fear                   73\n",
      "Social_event_attendance      62\n",
      "Going_outside                66\n",
      "Drained_after_socializing    52\n",
      "Friends_circle_size          77\n",
      "Post_frequency               65\n",
      "Personality                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"data/personality_dataset.csv\")\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5d75f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape: (2900, 7)\n",
      "Processed X shape: (2900, 9)\n",
      "Original y shape: (2900,)\n",
      "Encoded y shape: (2900,)\n",
      "Sample of encoded y: [0 1 1 0 0]\n",
      "Sample of processed X (first 5 rows, first 5 columns):\n",
      " [[ 4.  4.  6. 13.  5.]\n",
      " [ 9.  0.  0.  0.  3.]\n",
      " [ 9.  1.  2.  5.  2.]\n",
      " [ 0.  6.  7. 14.  8.]\n",
      " [ 3.  9.  4.  8.  5.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Separate target variable\n",
    "X = df.drop(\"Personality\", axis=1)\n",
    "y = df[\"Personality\"]\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "numerical_cols = X.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "\n",
    "# Preprocessing pipelines for numerical and categorical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Create a preprocessor object using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer, numerical_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(f\"Original X shape: {X.shape}\")\n",
    "print(f\"Processed X shape: {X_processed.shape}\")\n",
    "print(f\"Original y shape: {y.shape}\")\n",
    "print(f\"Encoded y shape: {y_encoded.shape}\")\n",
    "print(\"Sample of encoded y:\", y_encoded[:5])\n",
    "print(\"Sample of processed X (first 5 rows, first 5 columns):\\n\", X_processed[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abf3d35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp311-cp311-win_amd64.whl (10.7 MB)\n",
      "     ---------------------------------------- 10.7/10.7 MB 4.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\pcadmin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (2.2.5)\n",
      "Collecting scipy>=1.8.0\n",
      "  Downloading scipy-1.15.3-cp311-cp311-win_amd64.whl (41.2 MB)\n",
      "     ---------------------------------------- 41.2/41.2 MB 4.5 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.7.0 scipy-1.15.3 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11587ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best Hyperparameters: {'classifier__bootstrap': True, 'classifier__max_depth': None, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 100}\n",
      "\n",
      "Training Set Evaluation:\n",
      "Accuracy: 0.9366\n",
      "Precision: 0.9368\n",
      "Recall: 0.9366\n",
      "F1-Score: 0.9366\n",
      "\n",
      "Testing Set Evaluation:\n",
      "Accuracy: 0.9293\n",
      "Precision: 0.9296\n",
      "Recall: 0.9293\n",
      "F1-Score: 0.9293\n",
      "Confusion Matrix:\n",
      " [[278  24]\n",
      " [ 17 261]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# Define the preprocessor (update according to your pipeline)\n",
    "# Example: Assuming 'preprocessor' is already defined as part of your pipeline\n",
    "# preprocessor = ... \n",
    "\n",
    "# Hyperparameter grid for RandomForestClassifier\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__bootstrap': [True, False],\n",
    "}\n",
    "\n",
    "# Create the pipeline with preprocessing and classifier\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters and the corresponding model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "print(\"\\nTraining Set Evaluation:\")\n",
    "print(f\"Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Precision: {train_precision:.4f}\")\n",
    "print(f\"Recall: {train_recall:.4f}\")\n",
    "print(f\"F1-Score: {train_f1:.4f}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nTesting Set Evaluation:\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"F1-Score: {test_f1:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", test_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12a7df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9224\n",
      "Precision: 0.9088\n",
      "Recall: 0.9317\n",
      "F1-Score: 0.9201\n",
      "Confusion Matrix:\n",
      " [[276  26]\n",
      " [ 19 259]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Create the full pipeline with preprocessing and model\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00b95c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data prediction: Extrovert\n"
     ]
    }
   ],
   "source": [
    "# Example of making a prediction on new data\n",
    "# Let's create a sample new data point (ensure it has the same columns as the training data)\n",
    "new_data = pd.DataFrame([{\n",
    "    'Time_spent_Alone': 5,\n",
    "    'Stage_fear': 'No',\n",
    "    'Social_event_attendance': 3,\n",
    "    'Going_outside': 7,\n",
    "    'Drained_after_socializing': 'No',\n",
    "    'Friends_circle_size': 10,\n",
    "    'Post_frequency': 6\n",
    "}])\n",
    "\n",
    "# Make prediction\n",
    "new_prediction_encoded = best_model.predict(new_data)\n",
    "new_prediction_personality = label_encoder.inverse_transform(new_prediction_encoded)\n",
    "\n",
    "print(f\"New data prediction: {new_prediction_personality[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4d989e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
